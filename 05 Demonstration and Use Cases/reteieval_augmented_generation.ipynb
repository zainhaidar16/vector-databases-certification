{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Retrieval-Augmented Generation (RAG)** is a technique that helps improve the answers provided by large language models (like ChatGPT) by giving them additional relevant information before they generate a response. Here's a step-by-step breakdown:\n",
    "\n",
    "-  Imagine you have a question about a specific topic (e.g., animals). You first search a special database (vector database) that stores information in a way that helps find similar concepts.\n",
    "\n",
    "- Retrieve Relevant Information: The database returns the most relevant pieces of information related to your query (e.g., facts about elephants and other animals).\n",
    "\n",
    "- Build a Prompt: You then create a prompt (a set of instructions) that includes the retrieved information. This is like gathering notes before writing an essay.\n",
    "\n",
    "- Generate an Answer: Finally, you feed this prompt into the language model (like ChatGPT), which uses the provided information to generate a more accurate and informed answer.\n",
    "\n",
    "\n",
    "In simple terms, RAG is like doing a quick research before answering a question, ensuring that the response is based on the most relevant and up-to-date information available. This helps the language model provide better and more accurate answers, even if it wasn't originally trained on that specific information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Vector Databases\\vector-databases-certification\\env\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:112: UserWarning: Protobuf gencode version 5.27.2 is older than the runtime version 5.28.0 at grpc_health/v1/health.proto. Please avoid checked-in Protobuf gencode that can be obsolete.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "import json\n",
    "import weaviate\n",
    "from weaviate.embedded import EmbeddedOptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "10\n",
      "{\n",
      "  \"Category\": \"SCIENCE\",\n",
      "  \"Question\": \"This organ removes excess glucose from the blood & stores it as glycogen\",\n",
      "  \"Answer\": \"Liver\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# download the data\n",
    "# Downlaod the data https://raw.githubusercontent.com/weaviate-tutorials/quickstart/main/data/jeopardy_tiny.json\n",
    "response = requests.get('https://raw.githubusercontent.com/weaviate-tutorials/quickstart/main/data/jeopardy_tiny.json')\n",
    "data = json.loads(response.text)\n",
    "\n",
    "# Parse the json and preview the data using json_prin function\n",
    "def json_print(data):\n",
    "    print(json.dumps(data, indent=2))\n",
    "\n",
    "print(type(data))\n",
    "print(len(data))\n",
    "print(json.dumps(data[0], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Vector Databases\\vector-databases-certification\\env\\Lib\\site-packages\\weaviate\\__init__.py:143: DeprecationWarning: Dep010: Importing AuthApiKey from weaviate is deprecated. Import AuthApiKey from its module: weaviate.auth\n",
      "  _Warnings.root_module_import(name, map_[name])\n",
      "d:\\Vector Databases\\vector-databases-certification\\env\\Lib\\site-packages\\weaviate\\warnings.py:162: DeprecationWarning: Dep016: Python client v3 `weaviate.Client(...)` connections and methods are deprecated. Update\n",
      "            your code to use Python client v4 `weaviate.WeaviateClient` connections and methods.\n",
      "\n",
      "            For Python Client v4 usage, see: https://weaviate.io/developers/weaviate/client-libraries/python\n",
      "            For code migration, see: https://weaviate.io/developers/weaviate/client-libraries/python/v3_v4_migration\n",
      "            \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client is ready: True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'client = weaviate.Client(\\n    url=\"https://e2pxfwhqioinxijlmnqxw.c0.europe-west3.gcp.weaviate.cloud\",\\n    auth_client_secret=auth_config,\\n    additional_headers={\\n        \"X-Cohere-Api-Key\": cohere_api_key\\n        #\"X-Google-Studio-Api-Key\": ai_studio_api_key\\n        #\"X-OpenAI-Api-Key\": openai_api_key\\n    }\\n)'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data into Weaviate\n",
    "cohere_api_key = os.getenv(\"COHERE_APIKEY\")\n",
    "\n",
    "waeivate_api_key = os.getenv(\"WEAVIATE_API_KEY\")\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API\")\n",
    "\n",
    "auth_config = weaviate.AuthApiKey(api_key=waeivate_api_key)\n",
    "\n",
    "# Connect to the locallay launched instance of Weaviate\n",
    "client = weaviate.Client(\n",
    "        url = \"http://localhost:8080\",\n",
    "        additional_headers={\n",
    "        \"X-Cohere-Api-Key\": cohere_api_key\n",
    "        #\"X-Google-Studio-Api-Key\": ai_studio_api_key\n",
    "        #\"X-OpenAI-Api-Key\": openai_api_key\n",
    "    }\n",
    "\n",
    "    )\n",
    "\n",
    "print(f\"Client is ready: {client.is_ready()}\")\n",
    "\n",
    "\"\"\"client = weaviate.Client(\n",
    "    url=\"https://e2pxfwhqioinxijlmnqxw.c0.europe-west3.gcp.weaviate.cloud\",\n",
    "    auth_client_secret=auth_config,\n",
    "    additional_headers={\n",
    "        \"X-Cohere-Api-Key\": cohere_api_key\n",
    "        #\"X-Google-Studio-Api-Key\": ai_studio_api_key\n",
    "        #\"X-OpenAI-Api-Key\": openai_api_key\n",
    "    }\n",
    ")\"\"\"\n",
    "\n",
    "#print(\"client created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Deleted Successfully\n"
     ]
    }
   ],
   "source": [
    "# Check and delete already existed class\n",
    "if client.schema.exists(\"Question\"):\n",
    "    client.schema.delete_class(\"Question\")\n",
    "print(\"Class Deleted Successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class created\n"
     ]
    }
   ],
   "source": [
    "# Create class object\n",
    "class_obj = {\n",
    "    \"class\": \"Question\",\n",
    "    \"vectorizer\": \"text2vec-cohere\",\n",
    "}\n",
    "\n",
    "client.schema.create_class(class_obj)\n",
    "print(\"Class created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing question: 1\n",
      "importing question: 2\n",
      "importing question: 3\n",
      "importing question: 4\n",
      "importing question: 5\n",
      "importing question: 6\n",
      "importing question: 7\n",
      "importing question: 8\n",
      "importing question: 9\n",
      "importing question: 10\n"
     ]
    }
   ],
   "source": [
    "with client.batch.configure() as batch:\n",
    "    for i, d in enumerate(data):  # Batch import data\n",
    "        \n",
    "        print(f\"importing question: {i+1}\")\n",
    "        \n",
    "        properties = {\n",
    "            \"answer\": d[\"Answer\"],\n",
    "            \"question\": d[\"Question\"],\n",
    "            \"category\": d[\"Category\"],\n",
    "        }\n",
    "        \n",
    "        batch.add_data_object(\n",
    "            data_object=properties,\n",
    "            class_name=\"Question\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"data\": {\n",
      "    \"Aggregate\": {\n",
      "      \"Question\": [\n",
      "        {\n",
      "          \"meta\": {\n",
      "            \"count\": 10\n",
      "          }\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "json_print(client.query.aggregate('Question').with_meta_count().do())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"data\": {\n",
      "    \"Get\": {\n",
      "      \"Question\": [\n",
      "        {\n",
      "          \"answer\": \"Elephant\"\n",
      "        },\n",
      "        {\n",
      "          \"answer\": \"Antelope\"\n",
      "        },\n",
      "        {\n",
      "          \"answer\": \"the nose or snout\"\n",
      "        },\n",
      "        {\n",
      "          \"answer\": \"the diamondback rattler\"\n",
      "        },\n",
      "        {\n",
      "          \"answer\": \"Liver\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# write a query for vector search related to the concept animals\n",
    "repsonse = (\n",
    "    client.query.get('Question', 'answer')\n",
    "    .with_near_text({\"concepts\": \"animals\"})\n",
    "    .with_limit(5)\n",
    "    .do()\n",
    ")\n",
    "\n",
    "print(json.dumps(repsonse, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass each of these objects to a LLM individually to use when answering a prompt\n",
    "\n",
    "# write a prompt that uses the animal object and passes it to the LLM\n",
    "prompt = \"Tell me a story about this animal {answer}!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"data\": {\n",
      "    \"Get\": {\n",
      "      \"Question\": [\n",
      "        {\n",
      "          \"_additional\": {\n",
      "            \"generate\": {\n",
      "              \"error\": null,\n",
      "              \"singleResult\": \"Once upon a time, there was an elephant named Elmer who lived in the lush, green forests of Africa. Elmer was a big, strong elephant with a huge, curved tusk that protruded from his left jaw. He was proud of his tusk and used it to dig up roots and move heavy branches out of his way.\\n\\nElmer spent most of his days wandering the forest, searching for delicious leaves and branches to eat. He loved the taste of fresh bamboo shoots and could smell them from miles away. His trunk was incredibly sensitive, and he could use it to pick up even the tiniest of objects.\\n\\nOne day, Elmer came across a strange sight in the middle of the forest. It was a small, round pool of water with a shiny, smooth surface. Elmer was curious and decided to take a closer look. As he leaned in, he caught a glimpse of his reflection in the water and was startled by the sight of his own enormous form. He trumpeted loudly, causing the water to ripple and distort the image. Elmer was fascinated by this mysterious pool and decided to use his mighty tusk to carve a larger, clearer pool, which would reflect his image accurately.\\n\\nFor days, Elmer worked tirelessly, using his tusk and powerful legs to shape the pool. He cleared away rocks and branches, smoothed the edges, and created a perfect, mirror-like surface. Other elephants joined him in this task, drawn by his determination and curiosity. Together, they shaped the pool, taking turns to admire their reflections in the water.\\n\\nThe news of this wondrous place spread throughout the forest, and soon, many animals came to visit the magical pool. Birds, monkeys, and even small insects gathered around it. Elmer and the other elephants allowed them to share this special place, as long as they kept the pool clean and respected the elephants' space.\\n\\nThe pool became a popular spot for all the animals to admire their reflections and cool off during the hot days. Elmer was proud that he had created something that brought the creatures of the forest together. He posed proudly, showing off his majestic tusks and enormous ears to all the admiring animals.\\n\\nAnd so, the magical reflecting pool became a sanctuary for the animals of the forest, all thanks to Elmer's curiosity, determination, and love for his own reflection. The elephants especially cherished this place and visited it often, enjoying the cool water and the sight of their majestic images.\\n\\nThe End.\"\n",
      "            }\n",
      "          },\n",
      "          \"answer\": \"Elephant\"\n",
      "        },\n",
      "        {\n",
      "          \"_additional\": {\n",
      "            \"generate\": {\n",
      "              \"error\": null,\n",
      "              \"singleResult\": \"Amidst the lush grasslands, a proud antelope gracefully roamed. With long, slender legs and alert ears, it moved with an effortless grace. This creature, a symbol of agility and beauty, was a joy to behold.\\n\\nThe antelope, a master of survival, possessed keen senses and incredible speed. Its coat, a mosaic of rich brown and golden hues, seamlessly blended into the surrounding terrain, providing an indispensable camouflage. It navigated the grassy plains with ease, effortlessly transitioning from leisurely grazes to swift dashes with fluidity.\\n\\nAs the sun traversed the vast sky, the antelope found itself near a lush waterhole, a popular meeting place amidst the heat of the day. There, it encountered other antelopes, and the group formed a peaceful herd. They shared affectionate nuzzles and playful gestures, fostering a strong sense of camaraderie.\\n\\nBut the serene scene didn't last forever. A distant, deep rumble echoed across the plains, signaling the approach of a formidable predator - the lion. The antelopes' alertness surged, and their eyes darted anxiously in search of an escape route. With lightning speed, the antelope fleeted away, their hooves kicking up dust as they sprinted across the terrain. In a coordinated effort, the herd maintained a cohesive front, ensuring that the younger and weaker members were protected within the center.\\n\\nThe lion's pursuit was relentless, its powerful roar reverberating through the air. But the antelope's advantage lay in their agility and knowledge of the terrain. They maneuvered through the landscape with skillful precision, using their sharp vision to navigate the safest path. The lion, though formidable, couldn't match the antelope's swiftness and eventually relented, returning to the comfort of its den.\\n\\nThe antelope herd, victorious, continued their journey, their graceful forms blending seamlessly with the setting sun. They represented not just creatures of beauty but symbols of resilience and survival, adapting to the ever-changing African landscape.\\n\\nAnd so, the story of this antelope, a creature of the grasslands, concludes with a reminder of the enduring spirit of nature and the enduring legacy of the animal kingdom.\"\n",
      "            }\n",
      "          },\n",
      "          \"answer\": \"Antelope\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Write a query to perform RAG\n",
    "response = (client.query\n",
    "            .get(\"Question\", \"answer\")\n",
    "            .with_near_text({\"concepts\": \"animals\"})\n",
    "            .with_generate(single_prompt=prompt)\n",
    "            .with_limit(2)\n",
    "            .do()\n",
    "            )\n",
    "\n",
    "json_print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"data\": {\n",
      "    \"Get\": {\n",
      "      \"Question\": [\n",
      "        {\n",
      "          \"category\": \"ANIMALS\"\n",
      "        },\n",
      "        {\n",
      "          \"category\": \"ANIMALS\"\n",
      "        },\n",
      "        {\n",
      "          \"category\": \"ANIMALS\"\n",
      "        },\n",
      "        {\n",
      "          \"category\": \"ANIMALS\"\n",
      "        },\n",
      "        {\n",
      "          \"category\": \"SCIENCE\"\n",
      "        },\n",
      "        {\n",
      "          \"category\": \"SCIENCE\"\n",
      "        },\n",
      "        {\n",
      "          \"category\": \"SCIENCE\"\n",
      "        },\n",
      "        {\n",
      "          \"category\": \"SCIENCE\"\n",
      "        },\n",
      "        {\n",
      "          \"category\": \"SCIENCE\"\n",
      "        },\n",
      "        {\n",
      "          \"category\": \"SCIENCE\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Extract All Categories\n",
    "response = (client.query\n",
    "            .get(\"Question\", 'category')\n",
    "            .with_near_text({'concepts':'animals'})\n",
    "            .with_limit(10)\n",
    "            .do()\n",
    "           )\n",
    "\n",
    "json_print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a prompt that will requires information from all returned objects\n",
    "prompt = \"Which of these subjects {category} does a zoologist specialize in?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"data\": {\n",
      "    \"Get\": {\n",
      "      \"Question\": [\n",
      "        {\n",
      "          \"_additional\": {\n",
      "            \"generate\": {\n",
      "              \"error\": null,\n",
      "              \"groupedResult\": \"A zoologist would specialize in the category of ANIMALS.\"\n",
      "            }\n",
      "          },\n",
      "          \"category\": \"ANIMALS\"\n",
      "        },\n",
      "        {\n",
      "          \"_additional\": null,\n",
      "          \"category\": \"ANIMALS\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Write a query to perform RAG with grouped response\n",
    "response = (client.query\n",
    "            .get(\"Question\", \"category\")\n",
    "            .with_near_text({\"concepts\": \"animals\"})\n",
    "            .with_generate(grouped_task=prompt)\n",
    "            .with_limit(2)\n",
    "            .do()\n",
    "            )\n",
    "json_print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
